{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random to intialize random perceptron weights (if required)\n",
    "# Numpy for vectors,matrices and dot products\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining a perceptron\n",
    "\n",
    "class linearPerceptron(object):\n",
    "    \n",
    "    def __init__(self, num_inputs, weight_vector = None):\n",
    "        # Defining the initial perceptron\n",
    "        self.num_inputs = num_inputs\n",
    "        if(weight_vector == None):\n",
    "            self.weights = [rd.random() for i in range(num_inputs)]\n",
    "        else:\n",
    "            if(len(weight_vector) != num_inputs):\n",
    "                raise Exception(\"Weight vector size invalid. Must be #Inputs + 1\")\n",
    "            else:\n",
    "                self.weights = weight_vector\n",
    "        self.weights = np.array(self.weights)\n",
    "        self.output = None\n",
    "        self.iterError = []\n",
    "        self.weightUpdates = []  \n",
    "        self.minError = None\n",
    "        self.runIters = 0\n",
    "\n",
    "    \n",
    "    def computePerceptronOutput(self, input_vector):\n",
    "        # Computes the output as a combination of inputs\n",
    "        if(type(input_vector) is np.array):\n",
    "            print \"Input not a numpy array\"\n",
    "        else:\n",
    "            if(self.weights.size == input_vector.size):   \n",
    "                self.output = np.dot(self.weights, input_vector)\n",
    "            else:\n",
    "                print \"Inputs provided is of invalide size\"\n",
    "    \n",
    "                \n",
    "    def computeError(self,input_matrix, target_vector):\n",
    "        # Compute errors in the current weight training\n",
    "        \n",
    "        outputVector = []\n",
    "        \n",
    "        nTrain = len(input_matrix) # Size of training input\n",
    "        \n",
    "        for input_vector in input_matrix:\n",
    "            self.computePerceptronOutput(input_vector)\n",
    "            outputVector = np.append(outputVector,self.output)\n",
    "        \n",
    "        if(len(target_vector) != nTrain):\n",
    "            raise Exception(\"Training Vector provided is not of the same size as inputs\")\n",
    "\n",
    "        error_vector = np.subtract(target_vector,outputVector)\n",
    "        error_squared = [x * x for x in error_vector]\n",
    "        totalError = sum(error_squared) * 0.5\n",
    "        updateSize = np.dot(error_vector,input_matrix)\n",
    "        return totalError,updateSize\n",
    "    \n",
    "    \n",
    "    def trainBatchGradientDescent(self, input_matrix, target_vector, alpha = 0.01, nIter = 100):\n",
    "        # Batch Gradient Descent is performed on the linear Perceptron given\n",
    "        # the input matrix and a target vector to be learnt at learning Rate (alpha)\n",
    "        # The batch descent is by default set to run only 100 iterations\n",
    "        print \"Training with Batch Gradient Descent....! Plz Wait..!\"\n",
    "        \n",
    "        # Input matrix is number_of_inputs X no. of training examples\n",
    "        \n",
    "        self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "        \n",
    "        nInput = self.num_inputs\n",
    "        \n",
    "        self.minError,updateSizes = self.computeError(input_matrix = input_matrix,target_vector = target_vector)\n",
    "        self.iterError = np.append(self.iterError,self.minError)\n",
    "        \n",
    "        converged = 0\n",
    "        \n",
    "        for i in range(nIter):\n",
    "            outputVector = np.array([])\n",
    "            \n",
    "            totalError,updateSizes = self.computeError(input_matrix,target_vector)\n",
    "            \n",
    "            deltaWeights = alpha * updateSizes\n",
    "            \n",
    "            # UpdateWeights\n",
    "            oldWeights = self.weights\n",
    "            newWeights = np.add(self.weights,deltaWeights)\n",
    "            self.weights = newWeights\n",
    "            \n",
    "            totalError,updateSizes = self.computeError(input_matrix,target_vector)\n",
    "            \n",
    "            if(totalError >= self.minError):\n",
    "                converged = 1\n",
    "                self.runIters = i\n",
    "                self.weights = oldWeights\n",
    "                print \"Converged.....!\"\n",
    "                print self.weights\n",
    "                return\n",
    "            else:\n",
    "                self.minError = totalError\n",
    "                self.weights = newWeights\n",
    "                self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "                self.iterError = np.append(self.iterError,self.minError)\n",
    "\n",
    "        \n",
    "        print \"Ran out of iterations without converging......! Tough luck matey...!\"\n",
    "        print self.weights      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate training examples to learn the function\n",
    "# x1 + 2 * x2 > 2\n",
    "\n",
    "nInputs = 250\n",
    "\n",
    "x1 = [rd.random() for i in range(nInputs)]\n",
    "meanx1 = np.mean(x1)\n",
    "sdx1 = np.std(x1)\n",
    "x1 = [round((x-meanx1)/sdx1,3) for x in x1]\n",
    "x1 = np.array(x1)\n",
    "\n",
    "x2 = [rd.random() for i in range(nInputs)]\n",
    "meanx2 = np.mean(x2)\n",
    "sdx2 = np.std(x2)\n",
    "x2 = [round((x-meanx2)/sdx2,3) for x in x2]\n",
    "x2 = np.array(x2)\n",
    "\n",
    "inputMatrix = []\n",
    "outputVector = []\n",
    "\n",
    "for i in range(nInputs):\n",
    "    inputMatrix.append([x1[i],x2[i]])\n",
    "    outputVector.append(1 if ((x1[i] + 2 * x2[i] - 2) > 0) else 0)\n",
    "    \n",
    "inputMatrix = np.array(inputMatrix)\n",
    "outputVector = np.array(outputVector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn = np.random.randn(250) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train = inputMatrix[trn]\n",
    "trainOutput = outputVector[trn]\n",
    "print len(train)\n",
    "print len(trainOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "test = inputMatrix[~trn]\n",
    "testOutput = outputVector[~trn]\n",
    "print len(test)\n",
    "print len(testOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lp1 = linearPerceptron(num_inputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Batch Gradient Descent....! Plz Wait..!\n",
      "Converged.....!\n",
      "[ 0.16369337  0.24662512]\n"
     ]
    }
   ],
   "source": [
    "lp1.trainBatchGradientDescent(alpha=0.001,input_matrix=train,target_vector=trainOutput,nIter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.08074992,  19.90802271,  17.18612843,  15.40839618,\n",
       "        14.24586871,  13.4847043 ,  12.9857194 ,  12.65820979,\n",
       "        12.44299047,  12.30139455,  12.20812859,  12.14662675,\n",
       "        12.10602594,  12.0791941 ,  12.06144309,  12.04968764,\n",
       "        12.04189499,  12.03672432,  12.03329025,  12.0310075 ,\n",
       "        12.02948878,  12.02847753,  12.02780366,  12.02735427,\n",
       "        12.02705437,  12.02685409,  12.02672025,  12.02663075,\n",
       "        12.02657088,  12.02653079,  12.02650394,  12.02648595,\n",
       "        12.02647389,  12.02646579,  12.02646036,  12.02645672,\n",
       "        12.02645427,  12.02645263,  12.02645152,  12.02645078,\n",
       "        12.02645028,  12.02644994,  12.02644972,  12.02644956,\n",
       "        12.02644946,  12.02644939,  12.02644935,  12.02644932,\n",
       "        12.02644929,  12.02644928,  12.02644927,  12.02644926,\n",
       "        12.02644926,  12.02644926,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,\n",
       "        12.02644925,  12.02644925,  12.02644925,  12.02644925,  12.02644925])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.iterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.runIters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7511780299259443"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.computeError(input_matrix=test,target_vector=testOutput)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
