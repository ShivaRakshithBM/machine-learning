{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random to intialize random perceptron weights (if required)\n",
    "# Numpy for vectors,matrices and dot products\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining a perceptron\n",
    "\n",
    "class linearPerceptron(object):\n",
    "    \n",
    "    def __init__(self, num_inputs, weight_vector = None):\n",
    "        # Defining the initial perceptron\n",
    "        self.num_inputs = num_inputs\n",
    "        if(weight_vector is None):\n",
    "            self.weights = [rd.random() for i in range(num_inputs)]\n",
    "        else:\n",
    "            if(len(weight_vector) != num_inputs):\n",
    "                raise Exception(\"Weight vector size invalid. Must be #Inputs + 1\")\n",
    "            else:\n",
    "                self.weights = weight_vector\n",
    "        self.weights = np.array(self.weights)\n",
    "        self.output = None\n",
    "        self.iterError = []\n",
    "        self.weightUpdates = []  \n",
    "        self.minError = None\n",
    "        self.runIters = 0\n",
    "        self.converged = 0\n",
    "\n",
    "    \n",
    "    def computePerceptronOutput(self, input_vector):\n",
    "        # Computes the output as a combination of inputs\n",
    "        if(type(input_vector) is np.array):\n",
    "            print \"Input not a numpy array\"\n",
    "        else:\n",
    "            if(self.weights.size == input_vector.size):   \n",
    "                self.output = np.dot(self.weights, input_vector)\n",
    "            else:\n",
    "                print \"Inputs provided is of invalide size\"\n",
    "    \n",
    "                \n",
    "    def computeError(self,input_matrix, target_vector):\n",
    "        # Compute errors in the current weight training\n",
    "        \n",
    "        outputVector = []\n",
    "        \n",
    "        nTrain = len(input_matrix) # Size of training input\n",
    "        \n",
    "        for input_vector in input_matrix:\n",
    "            self.computePerceptronOutput(input_vector)\n",
    "            outputVector = np.append(outputVector,self.output)\n",
    "        \n",
    "        if(len(target_vector) != nTrain):\n",
    "            raise Exception(\"Training Vector provided is not of the same size as inputs\")\n",
    "\n",
    "        error_vector = np.subtract(target_vector,outputVector)\n",
    "        error_squared = [x * x for x in error_vector]\n",
    "        totalError = sum(error_squared) * 0.5\n",
    "        updateSize = np.dot(error_vector,input_matrix)\n",
    "        return totalError,updateSize\n",
    "    \n",
    "    \n",
    "    def trainGradientDescent(self, input_matrix, target_vector, alpha = 0.01, nIter = 100, method = \"batch\"):\n",
    "        \n",
    "        \n",
    "        # Batch Gradient Descent is performed on the linear Perceptron given\n",
    "        # the input matrix and a target vector to be learnt at learning Rate (alpha)\n",
    "        # The batch descent is by default set to run only 100 iterations\n",
    "        if(method==\"batch\"):\n",
    "            print \"Training with Batch Gradient Descent....! Plz Wait..!\"\n",
    "\n",
    "            # Input matrix is number_of_inputs X no. of training examples\n",
    "\n",
    "            self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "\n",
    "            nInput = self.num_inputs\n",
    "\n",
    "            self.minError,updateSizes = self.computeError(input_matrix = input_matrix,target_vector = target_vector)\n",
    "            self.iterError = np.append(self.iterError,self.minError)\n",
    "\n",
    "            for i in range(nIter):\n",
    "\n",
    "                totalError,updateSizes = self.computeError(input_matrix,target_vector)\n",
    "\n",
    "                deltaWeights = alpha * updateSizes\n",
    "\n",
    "                # UpdateWeights\n",
    "                oldWeights = self.weights\n",
    "                newWeights = np.add(self.weights,deltaWeights)\n",
    "                self.weights = newWeights\n",
    "\n",
    "                totalError,updateSizes = self.computeError(input_matrix,target_vector)\n",
    "\n",
    "                if(totalError >= self.minError):\n",
    "                    self.converged = 1\n",
    "                    self.runIters = i\n",
    "                    self.weights = oldWeights\n",
    "                    print \"Converged.....!\"\n",
    "                    print self.weights\n",
    "                    return\n",
    "                else:\n",
    "                    self.minError = totalError\n",
    "                    self.weights = newWeights\n",
    "                    self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "                    self.iterError = np.append(self.iterError,self.minError)\n",
    "\n",
    "\n",
    "            print \"Ran out of iterations without converging......! Tough luck matey...!\"\n",
    "            print self.weights\n",
    "    \n",
    "        # For stochastic gradient descent\n",
    "        elif(method == \"stochastic\"):\n",
    "            \n",
    "            print \"Training with Stochastic Gradient Descent....! Plz Wait..!\" \n",
    "            \n",
    "            self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "\n",
    "            nInput = self.num_inputs\n",
    "            nTrain = len(input_matrix)\n",
    "            \n",
    "            self.minError,updateSizes = self.computeError(input_matrix = input_matrix,target_vector = target_vector)\n",
    "            self.iterError = np.append(self.iterError,self.minError)\n",
    "            \n",
    "            oldWeights = self.weights\n",
    "            \n",
    "            # Run through iterations\n",
    "            for i in range(nIter):\n",
    "                \n",
    "                # Run through all training examples\n",
    "                for j in range(nTrain):\n",
    "                    \n",
    "                    input_vector = input_matrix[j]\n",
    "                    current_output = target_vector[j]\n",
    "                    \n",
    "                    newWeights = self.weights\n",
    "                    \n",
    "                    self.computePerceptronOutput(input_vector)\n",
    "                    deltaWeights = alpha * (current_output - self.output) * input_vector\n",
    "\n",
    "                    newWeights = np.add(newWeights,deltaWeights)\n",
    "                    \n",
    "                    self.weights = newWeights\n",
    "\n",
    "                totalError,updateSizes = self.computeError(input_matrix,target_vector)\n",
    "\n",
    "                if(totalError > self.minError):\n",
    "                    self.converged = 1\n",
    "                    self.runIters = i\n",
    "                    self.weights = oldWeights\n",
    "                    self.minError = totalError\n",
    "                    self.iterError = np.append(self.iterError,totalError)\n",
    "                    self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "                    print \"Converged.....!\"\n",
    "                    print self.weights\n",
    "                    return\n",
    "\n",
    "                else:\n",
    "                    self.minError = totalError\n",
    "                    self.weightUpdates = np.append(self.weightUpdates,self.weights)\n",
    "                    self.iterError = np.append(self.iterError,self.minError)\n",
    "\n",
    "            print \"Ran out of iterations without converging......! Tough luck matey...!\"\n",
    "            print self.weights\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            print \"No valid method provided...! Must be either 'stochastic' or 'batch'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate training examples to learn the function\n",
    "# x1 + 2 * x2 > 2\n",
    "\n",
    "nInputs = 250\n",
    "\n",
    "x1 = [rd.random() for i in range(nInputs)]\n",
    "meanx1 = np.mean(x1)\n",
    "sdx1 = np.std(x1)\n",
    "x1 = [round((x-meanx1)/sdx1,3) for x in x1]\n",
    "x1 = np.array(x1)\n",
    "\n",
    "x2 = [rd.random() for i in range(nInputs)]\n",
    "meanx2 = np.mean(x2)\n",
    "sdx2 = np.std(x2)\n",
    "x2 = [round((x-meanx2)/sdx2,3) for x in x2]\n",
    "x2 = np.array(x2)\n",
    "\n",
    "inputMatrix = []\n",
    "outputVector = []\n",
    "\n",
    "for i in range(nInputs):\n",
    "    inputMatrix.append([x1[i],x2[i]])\n",
    "    outputVector.append(1 if ((x1[i] + 2 * x2[i] - 2) > 0) else 0)\n",
    "    \n",
    "inputMatrix = np.array(inputMatrix)\n",
    "outputVector = np.array(outputVector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn = np.random.randn(250) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "train = inputMatrix[trn]\n",
    "trainOutput = outputVector[trn]\n",
    "print len(train)\n",
    "print len(trainOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "test = inputMatrix[~trn]\n",
    "testOutput = outputVector[~trn]\n",
    "print len(test)\n",
    "print len(testOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Batch Gradient Descent....! Plz Wait..!\n",
      "Converged.....!\n",
      "[ 0.14776569  0.24380379]\n"
     ]
    }
   ],
   "source": [
    "# Training lp1 with Batch Gradient Descent\n",
    "lp1 = linearPerceptron(num_inputs=2,weight_vector=np.array([0,0]))\n",
    "lp1.trainGradientDescent(alpha=0.001,input_matrix=train,target_vector=trainOutput,nIter=100,method=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Stochastic Gradient Descent....! Plz Wait..!\n",
      "Converged.....!\n",
      "[ 0.25967013  0.76126948]\n"
     ]
    }
   ],
   "source": [
    "lp2 = linearPerceptron(num_inputs=2)\n",
    "lp2.trainGradientDescent(alpha=0.001,input_matrix=train,target_vector=trainOutput,nIter=100,method=\"stochastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19.5       ,  16.60699688,  14.74996846,  13.55793035,\n",
       "        12.7927503 ,  12.30157218,  11.98627781,  11.78388493,\n",
       "        11.65396493,  11.57056638,  11.51703077,  11.4826648 ,\n",
       "        11.46060427,  11.4464429 ,  11.43735223,  11.43151659,\n",
       "        11.42777047,  11.42536568,  11.42382194,  11.42283094,\n",
       "        11.42219478,  11.42178639,  11.42152422,  11.42135593,\n",
       "        11.42124789,  11.42117853,  11.42113401,  11.42110542,\n",
       "        11.42108707,  11.42107529,  11.42106773,  11.42106288,\n",
       "        11.42105976,  11.42105776,  11.42105648,  11.42105565,\n",
       "        11.42105512,  11.42105478,  11.42105456,  11.42105442,\n",
       "        11.42105433,  11.42105428,  11.42105424,  11.42105422,\n",
       "        11.4210542 ,  11.42105419,  11.42105418,  11.42105418,\n",
       "        11.42105418,  11.42105418,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,\n",
       "        11.42105417,  11.42105417,  11.42105417,  11.42105417,  11.42105417])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.iterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.runIters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1303092526522791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1.computeError(input_matrix=test,target_vector=testOutput)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.32600862,  30.12116366,  23.94874643,  19.81045224,\n",
       "        17.03651057,  15.17758566,  13.93224313,  13.09828128,\n",
       "        12.54007518,  12.16666558,  11.91705724,  11.75035504,\n",
       "        11.63914594,  11.56505904,  11.51578693,  11.48308763,\n",
       "        11.46144432,  11.44716648,  11.43778714,  11.43165867,\n",
       "        11.42768193,  11.42512465,  11.42349983,  11.42248428,\n",
       "        11.42186407,  11.42149809,  11.42129363,  11.42119013,\n",
       "        11.42114827,  11.42114279,  11.42115762])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp2.iterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp2.runIters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
