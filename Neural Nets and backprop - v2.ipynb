{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and the Backprop algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document aims to build neural networks and train them through the various flavors of the backprop algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the functions that are needed \n",
    "- sigmoid() computes the logistic function\n",
    "- dotProduct() checks if 2 vectors are numpy arrays and performs dot products - Wrapper\n",
    "- vectorSubtract() and vectorAdd() perform subtraction and addition similary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(inputSignal):\n",
    "    return 1/(1 + (np.exp(-1 * inputSignal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dotProduct(numpyVector1,numpyVector2):\n",
    "    if not(isinstance(numpyVector1,np.ndarray)):\n",
    "        numpyVector1 = np.array(numpyVector1)\n",
    "    if not(isinstance(numpyVector2,np.ndarray)):\n",
    "        numpyVector2 = np.array(numpyVector2)\n",
    "    if numpyVector1.size != numpyVector2.size:\n",
    "        raise Exception(\"Dimensions do not match for dot product\")\n",
    "    else:\n",
    "        return np.dot(numpyVector1,numpyVector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorSubtract(numpyVector1,numpyVector2):\n",
    "    if not(isinstance(numpyVector1,np.ndarray)):\n",
    "        numpyVector1 = np.array(numpyVector1)\n",
    "    if not(isinstance(numpyVector2,np.ndarray)):\n",
    "        numpyVector2 = np.array(numpyVector2)\n",
    "    if numpyVector1.size != numpyVector2.size:\n",
    "        raise Exception(\"Dimensions do not match for vector subtraction\")\n",
    "    else:\n",
    "        return np.subtract(numpyVector1,numpyVector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorAdd(numpyVector1,numpyVector2):\n",
    "    if not(isinstance(numpyVector1,np.ndarray)):\n",
    "        numpyVector1 = np.array(numpyVector1)\n",
    "    if not(isinstance(numpyVector2,np.ndarray)):\n",
    "        numpyVector2 = np.array(numpyVector2)\n",
    "    if numpyVector1.size != numpyVector2.size:\n",
    "        raise Exception(\"Dimensions do not match for vector subtraction\")\n",
    "    else:\n",
    "        return np.add(numpyVector1,numpyVector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lookup table of activation functions\n",
    "actLookup = {\"sigmoid\":lambda x: sigmoid(x),\n",
    "                         \"linear\":lambda x: x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron Object that takes in the number of inputs and the type of activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuron(object):\n",
    "\n",
    "    # Defining a sigmoid neuron with n inputs and one output\n",
    "    def __init__(self, num_inputs, actFun = \"sigmoid\"):\n",
    "        \n",
    "        # Intialize with random weights\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = [rd.random() for i in (range(num_inputs + 1) )]\n",
    "        self.weights = np.array(self.weights)\n",
    "        \n",
    "        if(actFun not in ('linear','sigmoid','tanh')):\n",
    "            raise Exception(\"Unknown activation function. Input either sigmoid or tanh or linear\")\n",
    "\n",
    "        self.actFun = actLookup[actFun]\n",
    "        \n",
    "        self.output = None\n",
    "    \n",
    "    def computeOutput(self,inputVector):\n",
    "        \n",
    "        # Propagate the input and use activation function on the output        \n",
    "        propOut = dotProduct(self.weights, np.append(1,inputVector))\n",
    "        \n",
    "        self.output = self.actFun(propOut)\n",
    "        # Return the output to a function that can pass it on to next layer\n",
    "        return self.output\n",
    "        \n",
    "    def updateWeights(self, weightUpdate):\n",
    "        \n",
    "        # weightUpdates are usually applied during backpropagation\n",
    "        # Weight updates are applied all n + 1 input lines\n",
    "        self.weights = np.add(self.weights,weightUpdate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
