{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and the Backprop algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document aims to build neural networks and train them through the various flavors of the backprop algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the functions that are needed \n",
    "- sigmoid() computes the logistic function\n",
    "- dotProduct() checks if 2 vectors are numpy arrays and performs dot products - Wrapper\n",
    "- vectorSubtract() and vectorAdd() perform subtraction and addition similary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lookup table of activation functions\n",
    "actLookup = {\"sigmoid\":lambda x: sigmoid(x),\n",
    "                         \"linear\":lambda x: x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron Object that takes in the number of inputs and the type of activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuron(object):\n",
    "\n",
    "    # Defining a neuron with n inputs and one output\n",
    "    def __init__(self, numInputs, actFun = \"sigmoid\"):\n",
    "        \n",
    "        # Intialize with random weights\n",
    "        self.numInputs = numInputs\n",
    "        self.weights = [rd.random() for i in (range(numInputs + 1) )]\n",
    "        self.weights = np.array(self.weights)\n",
    "        \n",
    "        if(actFun not in ('linear','sigmoid','tanh')):\n",
    "            raise Exception(\"Unknown activation function. Input either sigmoid or tanh or linear\")\n",
    "\n",
    "        self.actFun = actLookup[actFun]\n",
    "        self.inputs = None\n",
    "        self.output = None\n",
    "    \n",
    "    def computeOutput(self,inputVector):\n",
    "        \n",
    "        self.inputs = inputVector\n",
    "        \n",
    "        if(not(isinstance(inputVector, np.ndarray))):\n",
    "            inputVector = np.array(inputVector)\n",
    "        \n",
    "        # Size of inputs (Say for batch learning)\n",
    "        batchSize, vectorSize = inputVector.shape()\n",
    "        \n",
    "        # Transpose the input vector and add a vector of 1s\n",
    "        inputVector = inputVector.T\n",
    "        inputVector = np.append(np.ones(batchSize).reshape(1,2),inputVector, axis = 0)\n",
    "        \n",
    "        # Propagate the input and use activation function on the output        \n",
    "        propOut = np.dot(self.weights, np.append(1,inputVector))\n",
    "        \n",
    "        self.output = self.actFun(propOut)\n",
    "        # Return the output to a function that can pass it on to next layer\n",
    "        return self.output\n",
    "    \n",
    "        \n",
    "    def updateWeights(self, weightUpdate):\n",
    "        \n",
    "        # weightUpdates are usually applied during backpropagation\n",
    "        # Weight updates are applied all n + 1 input lines\n",
    "        self.weights = np.add(self.weights,weightUpdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network layer that is composed of a layer of neurons of a defined type of activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuralNetworkLayer(object):\n",
    "    \n",
    "    # Defining a layer of neurons with a set of inputs fed into each neuron and one output from each of them\n",
    "    def __init__(self, numInputs, layerSize, actFun = 'sigmoid'):\n",
    "        \n",
    "        # Number of inputs and size of layer\n",
    "        self.numInputs = numInputs\n",
    "        self.layerSize = layerSize\n",
    "        \n",
    "        # If a vector of activation functions is defined, it needs to be equalt to the size of layer\n",
    "        if(isinstance(actFun,list)):\n",
    "            if(len(actFun) != self.layerSize):\n",
    "                raise Exception(\"Activation function vector is not same size as the network\")\n",
    "            else:\n",
    "                self.actFun = actFun\n",
    "        else:\n",
    "            print \"Single activation function assigned to all neurons\"\n",
    "            self.actFun = [actFun for i in range(layerSize)]\n",
    "            \n",
    "        self.neurons = [neuron(numInputs,actFun=self.actFun[i]) for i in range(self.layerSize)]\n",
    "        self.neuronInputs = None\n",
    "        self.neuronOut\n",
    "        \n",
    "    # Defining a forward function for the layer:\n",
    "    \n",
    "    def forward(self, inputVector):\n",
    "        \n",
    "        # Input vector is the input to each neuron as well as the layer as a whole\n",
    "        \n",
    "        if(not(isinstance(inputVector,np.ndarray))):\n",
    "            self.input = np.array(inputVector)\n",
    "        \n",
    "        # Each neuron computes the output fromt the input vector\n",
    "        self.output = [neuronUnit.computeOutput(inputVector) for neuronUnit in self.neurons]\n",
    "        return self.output\n",
    "    \n",
    "    # Calling a backward propagation on the layer\n",
    "    \n",
    "    def backward(self, delta, y):\n",
    "        \n",
    "        if(delta is None):\n",
    "            # Propagation rule for the last layer\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Propagation rule for hidden layer\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
