01/01 - Added code for neural nets. Need to complete derivations for batch and stochastic backprop algorithms

01/02 - Added new notebook with neural nets newer implementation. Layers are now built as objects and have forward and backward processes of their own

01/08 - Revamped structure of codes. Neural nets with sigmoid activation complete
Next steps - Test on MNIST dataset

01/10 - All operations vectorized. Accuracy on MNIST dataset 91.5%

02/11 - Added Regularization and He et al init for weights with Relu activations. Best accuracy with batch size of 5 and 20000 epochs. 8000 training MNIST Dataset
