{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "from mnist import MNIST as mn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lookup table of activation functions\n",
    "actLookup = {\"sigmoid\":lambda x: 1/(1 + np.exp(-1 * x)),\n",
    "                         \"linear\":lambda x: x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class layer(object):\n",
    "    # A neural net layer with n neurons as defined by the user and an activation function for the layer\n",
    "    \n",
    "    def __init__(self, numInputs, layerSize, actFun = \"sigmoid\"):\n",
    "        \n",
    "        # Size of the layer and the number of inputs\n",
    "        self.layerSize = layerSize\n",
    "        self.actFun = actFun\n",
    "        # Incorporating the bias neuron\n",
    "        self.numInputs = numInputs + 1\n",
    "        self.inputMatrix = None\n",
    "        \n",
    "        # Numpy matrix of weights\n",
    "        self.weights = np.array(np.random.randn(self.layerSize,self.numInputs))/100\n",
    "        \n",
    "        # Set the backward propagation values for this layer\n",
    "        self.delta = None\n",
    "        \n",
    "    # Defining the forward function to the layer\n",
    "    def forward(self, inputMatrix):\n",
    "        \"\"\"Forward() forward propagates the inputs to a layer\"\"\"\n",
    "        \n",
    "        # Convert to numpy array if not passed as a numpy array\n",
    "        if(not(isinstance(inputMatrix,np.ndarray))):\n",
    "            inputMatrix = np.array(inputMatrix)\n",
    "        \n",
    "        rows, columns = inputMatrix.shape\n",
    "        \n",
    "        # Dot product of input matrix (with extra 1s for the bias neuron) with the weight matrix\n",
    "        inputPadded = np.append(np.ones(rows).reshape(rows,1), inputMatrix, axis = 1)\n",
    "        self.inputMatrix = inputPadded\n",
    "        layerOutput = np.dot(inputPadded, self.weights.T)\n",
    "        \n",
    "        # Pass through activation function\n",
    "        self.output = actLookup[self.actFun](layerOutput)\n",
    "        return self.output\n",
    "    \n",
    "    # Defining the backward propagation function\n",
    "    def backward(self, trainTarget, delta):\n",
    "        \"\"\"Backward takes the delta from next layer and passes it on the previous layer\"\"\"\n",
    "        \n",
    "        if(not(isinstance(trainTarget,np.ndarray))):\n",
    "            trainTarget = np.array(trainTarget)\n",
    "        \n",
    "        # If delta is none then this layer is an output layere\n",
    "        if(delta is None):\n",
    "            \n",
    "            rows, columns = trainTarget.shape\n",
    "            errorTerm = np.subtract(trainTarget, self.output)\n",
    "            if self.actFun == \"sigmoid\":\n",
    "                outputInvert = np.array([(1. - op) for op in self.output])\n",
    "                term1 = np.multiply(outputInvert, self.output)\n",
    "                term2 = np.multiply(errorTerm, term1)\n",
    "                self.delta  = term2\n",
    "    \n",
    "\n",
    "        # If delta has been passed on to this layer, then this layer is a hidden layer\n",
    "        else:\n",
    "            \n",
    "            # Delta passed back is wkh * deltak for every batch instance\n",
    "            # Delta for each batch element is sum by column of the delta matrix passed back\n",
    "            # by the next layer\n",
    "            # deltaTerm3 = delta.sum(axis = 1)\n",
    "            deltaTerm3 = delta\n",
    "            \n",
    "            # note: need to add derivatives for other activation functions\n",
    "            if self.actFun == \"sigmoid\":\n",
    "                    \n",
    "                outputInvert = np.array([(1. - op) for op in self.output])\n",
    "                # Term1 represents o(1-o)\n",
    "                term1 = np.multiply(outputInvert, self.output)\n",
    "                self.delta = np.multiply(term1,deltaTerm3)\n",
    "        \n",
    "        # Delta to pass on to preceding layer has to be \n",
    "        # matrix multiplication of these values by the weight matrix\n",
    "        weightMatrix = self.weights[:,1:]\n",
    "        \n",
    "        deltaBack = weightMatrix.T.dot(self.delta.T)\n",
    "        return deltaBack.T\n",
    "    \n",
    "    def updateWeights(self, learnRate):\n",
    "        \"\"\"updateWeights() uses the inputs and the delta stored in each layer after forward\n",
    "        and backward propagation to derive the weight update rule\"\"\"\n",
    "        \n",
    "        # The udpate rule for each element in the matrix is given by\n",
    "        # wi = wi + sum_over_instances(delta for neuron * input i to neuron * learning rate)\n",
    "        # Compute the weight updates for every data point and then add those updates\n",
    "        rows,columns = self.inputMatrix.shape\n",
    "        weightUpdates = np.dot(self.inputMatrix.T,self.delta).T * (1/np.float(rows))\n",
    "        self.weights = np.add(self.weights,weightUpdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class neuralNet(object):\n",
    "    \n",
    "    \"\"\"Neural net object is a combination of layer objects. Has 2 functions\n",
    "    predict and backprop\"\"\"\n",
    "    \n",
    "    def __init__(self, layerList, actFun = \"sigmoid\"):\n",
    "        \n",
    "        \"\"\"Takes in the layerlist as input and generates as many layers\"\"\"\n",
    "        \n",
    "        # Activations to be used in the net\n",
    "        self.actFun = actFun\n",
    "        \n",
    "        # Creating the layers\n",
    "        self.layers = [layer(numInputs=layerList[i - 1],\n",
    "                             layerSize=layerList[i],                            \n",
    "                             actFun=self.actFun) for i in range(1, len(layerList))]\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return [layer.weights for layer in self.layers]\n",
    "        \n",
    "    def predict(self, inputMatrix):\n",
    "        \"\"\"Predict function is used to propagate the inputs from \n",
    "        one layer to the next and get the final output from the layer\"\"\"\n",
    "        # Pass on input of previous layer to the next\n",
    "        # If 1st hidden layer, pass on the input\n",
    "        layerOut = inputMatrix\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            layerOut = layer.forward(inputMatrix=layerOut)\n",
    "            \n",
    "        return layerOut\n",
    "    \n",
    "    def backprop(self, trainInput, trainOutput, learnRate, batchSize = 1, nIter = 100):\n",
    "        \"\"\"Back prop is used to update the weights based on the training sample\n",
    "        It runs nIter iterations on the trainInput with batchSize number of rows\n",
    "        Weight updates are carried out at learning rate learnRate\"\"\"\n",
    "        \n",
    "        if(not(isinstance(trainOutput,np.ndarray))):\n",
    "            trainOutput = np.array(trainOutput)\n",
    "        if(not(isinstance(trainInput,np.ndarray))):\n",
    "            trainInput = np.array(trainInput)\n",
    "        \n",
    "        rows, columns = trainInput.shape\n",
    "        \n",
    "        for i in range(nIter):\n",
    "            \n",
    "\n",
    "            \n",
    "            # Pick a random sample from the trainInput and trainOutput\n",
    "            # Updated weights based on the same. Sample size is to be of size batchSize\n",
    "            \n",
    "            randomIndices = np.random.choice(range(rows),size=batchSize)\n",
    "            \n",
    "            # Sample from trainInput and trainOutput\n",
    "            batchTrain = trainInput[randomIndices,:].reshape(batchSize,columns)\n",
    "            batchTest = trainOutput[randomIndices,:]\n",
    "        \n",
    "            # A forward pass through the network\n",
    "            self.predict(batchTrain)\n",
    "            \n",
    "            # Iterate backwards through the layers to pass the deltas\n",
    "            delta = None\n",
    "            \n",
    "                        # Show progress every 50 iterations or so\n",
    "            if i % 500 == 0:                \n",
    "                print i\n",
    "            \n",
    "            for layer in self.layers[::-1]:\n",
    "                \n",
    "                delta = layer.backward(trainTarget=batchTest,delta=delta)\n",
    "            \n",
    "                layer.updateWeights(learnRate=learnRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdata = mn(path='../datasets/MNIST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images,labels = mdata.load_training()\n",
    "images = np.array(images)/255.\n",
    "labels = np.array(labels).reshape(60000,1).astype(dtype = 'uint8')\n",
    "labels = np.unpackbits(labels,axis=1)\n",
    "labels = labels[:,4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleIndices = np.random.choice(range(len(images)),size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageTrain = images[sampleIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelTrain = labels[sampleIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testImages,testLabels = mdata.load_testing()\n",
    "testImages = np.array(testImages)/255.\n",
    "testLabelsDigit = np.array(testLabels).reshape(10000,1).astype(dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleTestIndices = np.random.choice(range(len(testImages)),size=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageTest = testImages[sampleTestIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelTest = testLabelsDigit[sampleTestIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training a neural net with 256 inputs, 300 hidden units (1 layer only)\n",
    "nn1 = neuralNet(layerList=[784,300,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "nn1.backprop(batchSize=20,learnRate=0.0001,nIter=10000,trainInput=imageTrain,trainOutput=labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = nn1.predict(imageTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.array([np.round(arr) for arr in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.append(np.zeros(4000).reshape(1000,4),preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predDigits = np.packbits(preds.astype(\"bool\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = [predDigits[i] == labelTest[i] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.915]\n"
     ]
    }
   ],
   "source": [
    "print sum(acc)/1000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
